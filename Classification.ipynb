{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on Textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification is the case of **Supervised Learning** where the target is always given. The explicit examples of output is provided what target model is supposed to produce for specific input. The data is split into an input space ${X}$ and an output space  ${Y}$\n",
    "\n",
    "$$\\Large{f:X->Y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this classifcation demo we are going to identify the genre of the text by using:\n",
    "    - Statistical Models\n",
    "        - Naive Bayes\n",
    "        - SVM \n",
    "    - Neural Network Models\n",
    "        - BiLSTM\n",
    "    - Pretrained Transformer Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have the news data. I am not sure from where I got this dataset but I don't claim this is my property or I created it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from TextPreProcessing import Preprocessing\n",
    "from sklearn import decomposition, ensemble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, string\n",
    "import spacy, pickle\n",
    "# Loading model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "business         610\n",
       "entertainment    486\n",
       "food              59\n",
       "graphics          65\n",
       "historical        22\n",
       "politics         517\n",
       "sport            298\n",
       "tech             413\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data using our favourite library pandas :D \n",
    "df = pd.read_csv(\"./train.csv\", sep=',',  encoding='utf8')\n",
    "# to see how much data we have on each class \n",
    "df.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing news and save them in new column\n",
    "preprocess = Preprocessing()\n",
    "df['cleanText'] = df['text'].apply(preprocess.normalizeText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>business</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>business</td>\n",
       "      <td>dollar gains on greenspan speech the dollar ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>business</td>\n",
       "      <td>yukos unit buyer faces loan claim the owners o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>business</td>\n",
       "      <td>high fuel prices hit ba s profits british airw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>business</td>\n",
       "      <td>pernod takeover talk lifts domecq shares in uk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...  business   \n",
       "1  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...  business   \n",
       "2  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...  business   \n",
       "3  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...  business   \n",
       "4  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...  business   \n",
       "\n",
       "                                           cleanText  \n",
       "0  ad sales boost time warner profit quarterly pr...  \n",
       "1  dollar gains on greenspan speech the dollar ha...  \n",
       "2  yukos unit buyer faces loan claim the owners o...  \n",
       "3  high fuel prices hit ba s profits british airw...  \n",
       "4  pernod takeover talk lifts domecq shares in uk...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[business, entertainment, politics, sport, tech, food, graphics, historical]\n",
       "Categories (8, object): [business, entertainment, politics, sport, tech, food, graphics, historical]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the labels into catgories (like 'business' -> 1, entertainment -> 2 etc) save them in new column labelCategory\n",
    "\n",
    "df['label'] = df['label'].astype('category')\n",
    "df['labelCategory'] = df['label'].cat.codes\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test split\n",
    "\n",
    "### This function from scikit-learn will randomly split the data into test and train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split\n",
    "trainX, testX, trainY, testY = model_selection.train_test_split(df['cleanText'], df['label']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering\n",
    "transform text data into feature vector. Features can be get using\n",
    "\n",
    "- Counter Vector: converting text to matrix \n",
    "- TF-IDF Vector\n",
    "     - Word level\n",
    "     - Character level\n",
    "     - N-Gram level\n",
    "- Word embeddings\n",
    "- Text/NLP based features\n",
    "- Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counter Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Counter Vector\n",
    "countVec = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "countVec.fit(df['text'].apply(lambda x: np.str_(x)))\n",
    "\n",
    "# transform the training and testing data using count vectorize object \n",
    "trainXCount = countVec.transform(trainX.apply(lambda x: np.str_(x)))\n",
    "testXCount = countVec.transform(testX.apply(lambda x: np.str_(x)))\n",
    "\n",
    "# to see the features countVec.get_feature_names()\n",
    "# print(testXCount.shape, trainXCount.shape, trainY.shape)\n",
    "\n",
    "# saving countVector to pickle file\n",
    "pickle.dump(countVec.vocabulary_, open(\"countVector.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Frequence Inverse Term Frequence (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level\n",
    "tfIDF = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfIDF.fit(df['cleanText'].apply(lambda x: np.str_(x)))\n",
    "trainX_TfIDF = tfIDF.transform(trainX.apply(lambda x: np.str_(x)))\n",
    "testX_TfIDF = tfIDF.transform(testX.apply(lambda x: np.str_(x)))\n",
    "pickle.dump(tfIDF, open(\"tfIDFWord.pkl\", \"wb\"))\n",
    "\n",
    "# ngram level \n",
    "tfIDF = TfidfVectorizer(token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "\n",
    "tfIDF.fit(df['cleanText'].apply(lambda x: np.str_(x)))\n",
    "trainX_TfIDFNgram = tfIDF.fit_transform(trainX.apply(lambda x: np.str_(x)))\n",
    "testX_TfIDFNgram = tfIDF.fit_transform(testX.apply(lambda x: np.str_(x)))\n",
    "pickle.dump(tfIDF, open(\"tfIDFNGram.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vector level\n",
    "tfIDF = TfidfTransformer()\n",
    "trainX_TfCount = tfIDF.fit_transform(trainXCount)\n",
    "testX_TfIDFCount = tfIDF.fit_transform(testXCount)\n",
    "pickle.dump(tfIDF, open(\"tfIDFCount.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTraining(model, trainX, trainY, testX):\n",
    "    \"\"\" \n",
    "        trainX = vectorized data\n",
    "        trainY = labels of 'vectorized data'\n",
    "        testY = test data \n",
    "    \"\"\"\n",
    "    classifier = model.fit(trainX, trainY)\n",
    "#     pickle.dump(model, open(\"modelMNB_VecCount_TfIDF.pkl\", \"wb\"))\n",
    "    pickle.dump(model, open(\"modelSVM_TfIDF.pkl\", \"wb\"))\n",
    "    predictions = classifier.predict(testX)\n",
    "    print(metrics.confusion_matrix(testY, predictions))\n",
    "    print(metrics.accuracy_score(predictions, testY) * 100)\n",
    "    print( metrics.classification_report(testY, predictions, target_names=  ['business', 'entertainment', 'politics', 'sport', 'tech', 'food', 'graphics', 'historical']))\n",
    "    return metrics.accuracy_score(predictions, testY) * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146   0   0   0   0   2   0   1]\n",
      " [  5 120   0   0   0  11   0   0]\n",
      " [  8   0   6   0   0   1   0   1]\n",
      " [  1   0   0   0   0   2   0  12]\n",
      " [  2   0   0   0   0   5   0   0]\n",
      " [  2   0   0   0   0 123   0   0]\n",
      " [  3   0   0   0   0  14  49   0]\n",
      " [  0   0   0   0   0   6   0  98]]\n",
      "87.70226537216828\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.87      0.98      0.92       149\n",
      "entertainment       1.00      0.88      0.94       136\n",
      "     politics       1.00      0.38      0.55        16\n",
      "        sport       0.00      0.00      0.00        15\n",
      "         tech       0.00      0.00      0.00         7\n",
      "         food       0.75      0.98      0.85       125\n",
      "     graphics       1.00      0.74      0.85        66\n",
      "   historical       0.88      0.94      0.91       104\n",
      "\n",
      "     accuracy                           0.88       618\n",
      "    macro avg       0.69      0.61      0.63       618\n",
      " weighted avg       0.86      0.88      0.86       618\n",
      "\n",
      "Naive Bayes accuracy-> tf-IDF Word level =  87.70226537216828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbnhm\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "# 1- vectorCount => 49%\n",
    "# accuracy = modelTraining(MultinomialNB(), trainXCount, trainY, testXCount) \n",
    "# print(\"Naive Bayes accuracy -> vectorCount = \", accuracy)\n",
    "# 2- tf-IDF Word level => 83.44\n",
    "# accuracy = modelTraining(MultinomialNB(), trainX_TfIDF, trainY, testX_TfIDF)\n",
    "# print(\"Naive Bayes accuracy-> tf-IDF Word level = \", accuracy)\n",
    "# # 3- tf-IDF n-gram uni and bigram level => 86.08, bi and trigram => 82.67\n",
    "# accuracy = modelTraining(MultinomialNB(), trainX_TfIDFNgram, trainY, testX_TfIDFNgram)\n",
    "# print(\"Naive Bayes accuracy-> tf-IDF n-gram = \", accuracy)\n",
    "# # 4- tf-IDF Vector Count transformer level => 87.05\n",
    "accuracy = modelTraining(MultinomialNB(), trainX_TfCount, trainY, testX_TfIDFCount)\n",
    "print(\"Naive Bayes accuracy-> tf-IDF Word level = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146   0   0   0   0   3   0   0]\n",
      " [  2 132   0   0   0   1   0   1]\n",
      " [  4   0  12   0   0   0   0   0]\n",
      " [  0   0   0  13   0   0   0   2]\n",
      " [  7   0   0   0   0   0   0   0]\n",
      " [  5   1   0   0   0 119   0   0]\n",
      " [  2   0   0   0   0   0  64   0]\n",
      " [  0   0   0   0   0   1   0 103]]\n",
      "95.30744336569579\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.88      0.98      0.93       149\n",
      "entertainment       0.99      0.97      0.98       136\n",
      "     politics       1.00      0.75      0.86        16\n",
      "        sport       1.00      0.87      0.93        15\n",
      "         tech       0.00      0.00      0.00         7\n",
      "         food       0.96      0.95      0.96       125\n",
      "     graphics       1.00      0.97      0.98        66\n",
      "   historical       0.97      0.99      0.98       104\n",
      "\n",
      "     accuracy                           0.95       618\n",
      "    macro avg       0.85      0.81      0.83       618\n",
      " weighted avg       0.95      0.95      0.95       618\n",
      "\n",
      "SVM accuracy-> tf-IDF n-gram =  95.30744336569579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbnhm\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 4- SVM => 50.16\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42)\n",
    "accuracy = modelTraining(svm.SVC(), trainX_TfCount, trainY, testX_TfIDFCount)\n",
    "print(\"SVM accuracy-> tf-IDF n-gram = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0161173db775b1ffc607617dcd93ca911c945389657c068f66f111a02f753df6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
